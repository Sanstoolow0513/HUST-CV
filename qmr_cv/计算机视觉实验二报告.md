# 上机实验二：基于卷积神经网络的两个数字比较

## 实验要求

	设计一个卷积神经网络，输入为两张MNIST手写体数字图片，如果两张图片为**同一个数字**（注意，非同一张图片），输出为1，否则为0。
	
	从MNIST数据集的训练集中选取10%作为本实验的训练图片，从MNIST数据集的测试集中选取10%作为本实验的测试图片。请将该部分图片经过适当处理形成一定数量的用于本次实验的训练集和测试集。

## 实验设计

这里给出两个思路
	1.我们可以训练一个网络用来做十分类任务，这样一个网络接受一个图像并输出数字，我们需要做的在封装成一个网络，输入为两个图像，输出为是否是同一个数字，这样就可以实现功能
	2.我们可以设计出一个提取出图片特征的卷积神经网络，然后通过比较两张图片的特征来判断数字是否相同的网络，其中数据集的准备可能需要设计（孪生神经网络（Siamese Network））

## 具体实现：我们使用思路一

### 数据处理

	- 使用`torchvision`库中的`datasets.MNIST`加载 MNIST 数据集。
	- 对数据进行预处理，通过`transforms.Compose`将数据转换为张量，并进行归一化处理，使用`transforms.ToTensor()`将图像转换为张量，`transforms.Normalize((0.5,), (0.5,))`对图像进行归一化，使数据具有零均值和单位方差，有助于模型的收敛。
	- 从 MNIST 数据集的训练集中选取 10% 作为本实验的训练图片，从测试集中选取 10% 作为本实验的测试图片。这里代码中未体现具体的 10% 数据选取逻辑，实际操作中可通过`torch.utils.data.Subset`来实现。例如，假设训练集有`n_train`个样本，可随机选取`int(n_train * 0.1)`个样本索引构建训练子集。
	- 使用`torch.utils.data.DataLoader`将数据集按指定的`batch_size`加载，训练集设置`batch_size = 64`并打乱顺序（`shuffle = True`），以增加训练的随机性，提高模型的泛化能力。测试集同样使用`DataLoader`加载，代码中设置`batch_size = 1`并打乱顺序。

### 分类网络具体设计
1. 基础分类网络
    - **卷积层**
        - 第一个卷积层`conv1`，输入通道数为 1（因为 MNIST 图像是灰度图），输出通道数为 32，卷积核大小为 3x3，填充为 1，这样可以保持图像的尺寸不变，通过卷积操作提取图像的低级特征。
        - 第二个卷积层`conv2`，输入通道数为 32（上一层的输出通道数），输出通道数为 64，卷积核大小和填充与第一层相同，进一步提取更高级的特征。
    - **池化层**
	    - 使用`nn.MaxPool2d(2, 2)`进行最大池化操作，池化核大小为 2x2，步长为 2，对卷积后的特征图进行下采样，减少数据量，同时保留重要特征。经过两次卷积和池化后，图像尺寸从初始的 28x28 变为 7x7。
    - **全连接层**
        - 第一个全连接层`fc1`，输入维度为`64 * 7 * 7`（池化后特征图的大小乘以通道数），输出维度为 128，将池化后的特征图展平并映射到一个 128 维的特征空间。
        - 第二个全连接层`fc2`，输入维度为 128，输出维度为 10，对应 MNIST 数据集中的 10 个数字类别，用于最终的分类。
    - **前向传播**
	    - 在`forward`方法中，数据依次经过卷积、激活函数（`nn.ReLU()`）、池化操作，然后展平进入全连接层，最后经过第二个全连接层输出分类结果。
1. 封装比较网络
    - **初始化**：接受一个预训练的基础分类模型`pretrained_model`，并将其作为`base_model`。
    - **前向传播**：输入两张图片`img1`和`img2`，分别通过`base_model`进行预测，得到`output1`和`output2`。然后通过`torch.argmax`获取每张图片预测的类别`pred1`和`pred2`，比较`pred1`和`pred2`是否相等，若相等则输出 1，否则输出 0，以判断两张图片是否为同一个数字。


## 实验结果
(QMR) C:\Users\Administrator\Desktop\HUST-CV>C:/ProgramData/anaconda3/envs/QMR/python.exe c:/Users/Administrator/Desktop/HUST-CV/CNN/qmr_2.py
Epoch 1, Loss: 0.16060853704238243
Epoch 2, Loss: 0.04521397541603272
Epoch 3, Loss: 0.03185065815546441
Epoch 4, Loss: 0.02248756464521489
Epoch 5, Loss: 0.01723942783284854
Label1: 3, Label2: 3, Same Digit: 1.0
在测试时，对一对测试图片进行预测，结果为`Label1: 3, Label2: 3, Same Digit: 1.0`，表明模型能够正确判断这两张图片为同一个数字。

我们使用更多的测试样例能够实现检测测试集，表现还可以

但是这样实现实际上有些问题，因为这样抽出来的测试集本身能够构成的对数较少难以检测的很好

## 实验分析

**分类网络**：
    - **优点**：更适合对输入特征明确且分类任务明确的场景。由于先训练一个基础的分类网络，该网络对数字的特征学习较为充分，在封装成比较网络时，训练速度相对较快，因为基础分类网络已经学习到了有效的特征表示。
    - **缺点**：性能高度依赖初始分类网络的性能。如果基础分类网络的准确率不高，那么封装后的比较网络的性能也会受到影响。
**Siamese 网络**：
    - **优点**：直接对特征相似性建模，在样本对的生成较合理时表现优异。它不需要预训练一个分类器，而是直接通过比较两张图片的特征来判断是否为同一个数字，能够更专注于特征的相似性度量。
    - **缺点**：样本对的生成需要精心设计，如果样本对的分布不合理，可能会导致模型学习效果不佳。同时，训练过程相对复杂，需要更多的调参技巧。
    -这里我学习一下了这个网络的构成，我认为这个网络更好的实现了功能