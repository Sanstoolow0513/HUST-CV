Microsoft Windows [版本 10.0.26100.2454]
(c) Microsoft Corporation。保留所有权利。

(QMR_CV) C:\Users\Administrator\Desktop\CV>cd lab1


(QMR_CV) C:\Users\Administrator\Desktop\CV\lab1>python lab.py
timer 1s
start
IF GPU READY: True
cuda
Epoch [1/1000], Loss: 0.43495383858680725
Epoch [2/1000], Loss: 0.1252753585577011
Epoch [3/1000], Loss: 0.09898000955581665
Epoch [4/1000], Loss: 0.04289599135518074
Epoch [5/1000], Loss: 0.04838382825255394
Epoch [6/1000], Loss: 0.3383536636829376
Epoch [7/1000], Loss: 0.669242799282074
Epoch [8/1000], Loss: 0.00785867776721716
Epoch [9/1000], Loss: 0.020429329946637154
Epoch [10/1000], Loss: 0.11201898008584976
Epoch [11/1000], Loss: 0.010556311346590519
Epoch [12/1000], Loss: 0.006589628756046295
Epoch [13/1000], Loss: 0.02782469056546688
Epoch [14/1000], Loss: 0.12472499161958694
Epoch [15/1000], Loss: 0.0013200318207964301
Epoch [16/1000], Loss: 0.004351520445197821
Epoch [17/1000], Loss: 0.01603573001921177
Epoch [18/1000], Loss: 0.0013222318375483155
Epoch [19/1000], Loss: 0.030724259093403816
Epoch [20/1000], Loss: 0.00717395031824708
Epoch [21/1000], Loss: 0.00022500490013044327
Epoch [22/1000], Loss: 0.0003578431496862322
Epoch [23/1000], Loss: 0.00021227785327937454
Epoch [24/1000], Loss: 0.015896810218691826
Epoch [25/1000], Loss: 0.0010087455157190561
Epoch [26/1000], Loss: 0.0052026729099452496
Epoch [27/1000], Loss: 0.08466660231351852
Epoch [28/1000], Loss: 0.042036596685647964
Epoch [29/1000], Loss: 0.00042970976210199296
Epoch [30/1000], Loss: 0.005196899641305208
Epoch [31/1000], Loss: 0.0010215904330834746
Epoch [32/1000], Loss: 0.003039306728169322
Epoch [33/1000], Loss: 0.0007977935019880533
Epoch [34/1000], Loss: 0.0007186562870629132
Epoch [35/1000], Loss: 0.09320303052663803
Epoch [36/1000], Loss: 0.5045337080955505
Epoch [37/1000], Loss: 0.020610524341464043
Epoch [38/1000], Loss: 0.00030253492877818644
Epoch [39/1000], Loss: 0.0006897569983266294
Epoch [40/1000], Loss: 0.001257840427570045
Epoch [41/1000], Loss: 0.031645726412534714
Epoch [42/1000], Loss: 0.010648957453668118
Epoch [43/1000], Loss: 0.001883618999272585
Epoch [44/1000], Loss: 0.00046964912326075137
Epoch [45/1000], Loss: 0.0013525442918762565
Epoch [46/1000], Loss: 0.0015362557023763657
Epoch [47/1000], Loss: 0.003612457774579525
Epoch [48/1000], Loss: 0.045838307589292526
Epoch [49/1000], Loss: 0.0045090327039361
Epoch [50/1000], Loss: 0.006343264132738113
Epoch [51/1000], Loss: 0.00011435092892497778
Epoch [52/1000], Loss: 0.005732732359319925
Epoch [53/1000], Loss: 0.0383780412375927
Epoch [54/1000], Loss: 0.668971061706543
Epoch [55/1000], Loss: 0.005878608673810959
Epoch [56/1000], Loss: 6.29007481620647e-05
Epoch [57/1000], Loss: 0.0014235234120860696
Epoch [58/1000], Loss: 0.1637076437473297
Epoch [59/1000], Loss: 0.24278712272644043
Epoch [60/1000], Loss: 3.3417760278098285e-05
Epoch [61/1000], Loss: 0.00022057561727706343
Epoch [62/1000], Loss: 7.358635048149154e-05
Epoch [63/1000], Loss: 0.026613300666213036
Epoch [64/1000], Loss: 0.1274430900812149
Epoch [65/1000], Loss: 0.0330190546810627
Epoch [66/1000], Loss: 0.00011836758494609967
Epoch [67/1000], Loss: 0.00020393422164488584
Epoch [68/1000], Loss: 0.0012268947903066874
Epoch [69/1000], Loss: 0.014262168668210506
Epoch [70/1000], Loss: 0.001289315870963037
Epoch [71/1000], Loss: 0.0007480738568119705
Epoch [72/1000], Loss: 0.0002810764708556235
Epoch [73/1000], Loss: 0.9124124646186829
Epoch [74/1000], Loss: 0.08236091583967209
Epoch [75/1000], Loss: 0.0037783498410135508
Epoch [76/1000], Loss: 0.009281900711357594
Epoch [77/1000], Loss: 1.3629428394779097e-05
Epoch [78/1000], Loss: 3.9020389522193e-05
Epoch [79/1000], Loss: 0.001457985956221819
Epoch [80/1000], Loss: 0.00015960593009367585
Epoch [81/1000], Loss: 0.0017640216974541545
Epoch [82/1000], Loss: 0.0007292294758372009
Epoch [83/1000], Loss: 0.003912897780537605
Epoch [84/1000], Loss: 4.0251517930300906e-05
Epoch [85/1000], Loss: 0.001086671371012926
Epoch [86/1000], Loss: 0.0022698824759572744
Epoch [87/1000], Loss: 0.005520978476852179
Epoch [88/1000], Loss: 0.007048042956739664
Epoch [89/1000], Loss: 0.0037846919149160385
Epoch [90/1000], Loss: 0.008828727528452873
Epoch [91/1000], Loss: 0.0014429489383473992
Epoch [92/1000], Loss: 0.014812071807682514
Epoch [93/1000], Loss: 0.0018428023904561996
Epoch [94/1000], Loss: 0.01058374997228384
Epoch [95/1000], Loss: 0.01243149396032095
Epoch [96/1000], Loss: 0.0003403575683478266
Epoch [97/1000], Loss: 0.0005215359851717949
Epoch [98/1000], Loss: 8.674029959365726e-05
Epoch [99/1000], Loss: 4.080787766724825e-05
Epoch [100/1000], Loss: 0.040742237120866776
Epoch [101/1000], Loss: 0.0018714270554482937
Epoch [102/1000], Loss: 0.00019200885435566306
Epoch [103/1000], Loss: 0.0027741941157728434
Epoch [104/1000], Loss: 0.2494957447052002
Epoch [105/1000], Loss: 0.002138130133971572
Epoch [106/1000], Loss: 0.00017408072017133236
Epoch [107/1000], Loss: 0.0016159970546141267
Epoch [108/1000], Loss: 0.008495667017996311
Epoch [109/1000], Loss: 0.017595022916793823
Epoch [110/1000], Loss: 0.025457531213760376
Epoch [111/1000], Loss: 0.0023188882041722536
Epoch [112/1000], Loss: 0.0003011543594766408
Epoch [113/1000], Loss: 0.0028676073998212814
Epoch [114/1000], Loss: 0.13597817718982697
Epoch [115/1000], Loss: 0.0021042798180133104
Epoch [116/1000], Loss: 0.12563519179821014
Epoch [117/1000], Loss: 0.006901187356561422
Epoch [118/1000], Loss: 0.020360907539725304
Epoch [119/1000], Loss: 0.04367561265826225
Epoch [120/1000], Loss: 0.0016383221372961998
Epoch [121/1000], Loss: 0.001044831587933004
Epoch [122/1000], Loss: 0.0019287107279524207
Epoch [123/1000], Loss: 0.00011995265958830714
Epoch [124/1000], Loss: 0.0030086322221904993
Epoch [125/1000], Loss: 2.344442918911227e-06
Epoch [126/1000], Loss: 0.00015881203580647707
Epoch [127/1000], Loss: 0.00024276426120195538
Epoch [128/1000], Loss: 3.456949343672022e-05
Epoch [129/1000], Loss: 0.008919662795960903
Epoch [130/1000], Loss: 0.03829440101981163
Epoch [131/1000], Loss: 2.9881071895943023e-05
Epoch [132/1000], Loss: 0.0002864050620701164
Epoch [133/1000], Loss: 0.022332338616251945
Epoch [134/1000], Loss: 0.0010531682055443525
Epoch [135/1000], Loss: 0.007039290387183428
Epoch [136/1000], Loss: 0.0005895384238101542
Epoch [137/1000], Loss: 0.02277492731809616
Epoch [138/1000], Loss: 0.00017556855164002627
Epoch [139/1000], Loss: 0.009998059831559658
Epoch [140/1000], Loss: 9.576415322953835e-06
Epoch [141/1000], Loss: 0.3055628836154938
Epoch [142/1000], Loss: 7.338939030887559e-05
Epoch [143/1000], Loss: 0.0013202006230130792
Epoch [144/1000], Loss: 0.043346624821424484
Epoch [145/1000], Loss: 0.008277652785182
Epoch [146/1000], Loss: 0.18693000078201294
Epoch [147/1000], Loss: 4.625069777830504e-05
Epoch [148/1000], Loss: 4.776152127305977e-05
Epoch [149/1000], Loss: 0.0011840916704386473
Epoch [150/1000], Loss: 0.2518516182899475
Epoch [151/1000], Loss: 0.00021690061839763075
Epoch [152/1000], Loss: 1.784140658855904e-05
Epoch [153/1000], Loss: 0.15454904735088348
Epoch [154/1000], Loss: 0.009522702544927597
Epoch [155/1000], Loss: 0.003997707273811102
Epoch [156/1000], Loss: 0.00044255773536860943
Epoch [157/1000], Loss: 0.00010183701670030132
Epoch [158/1000], Loss: 0.002473141299560666
Epoch [159/1000], Loss: 0.0006209924467839301
Epoch [160/1000], Loss: 0.005669170990586281
Epoch [161/1000], Loss: 0.00047127451398409903
Epoch [162/1000], Loss: 0.00011987132165813819
Epoch [163/1000], Loss: 0.01630178652703762
Epoch [164/1000], Loss: 0.0009275480988435447
Epoch [165/1000], Loss: 0.04722842574119568
Epoch [166/1000], Loss: 0.0005004527629353106
Epoch [167/1000], Loss: 9.471992234466597e-05
Epoch [168/1000], Loss: 0.0015362986596301198
Epoch [169/1000], Loss: 0.0004388008965179324
Epoch [170/1000], Loss: 5.642540145345265e-06
Epoch [171/1000], Loss: 0.0006143388454802334
Epoch [172/1000], Loss: 0.0012116795405745506
Epoch [173/1000], Loss: 6.318052328424528e-06
Epoch [174/1000], Loss: 5.701751433662139e-05
Epoch [175/1000], Loss: 0.000251179764745757
Epoch [176/1000], Loss: 1.943056849995628e-05
Epoch [177/1000], Loss: 5.217192301643081e-05
Epoch [178/1000], Loss: 0.06980284303426743
Epoch [179/1000], Loss: 0.6061694025993347
Epoch [180/1000], Loss: 7.910699787316844e-05
Epoch [181/1000], Loss: 0.8999428749084473
Epoch [182/1000], Loss: 0.0015431344509124756
Epoch [183/1000], Loss: 0.00048413980402983725
Epoch [184/1000], Loss: 0.001711640041321516
Epoch [185/1000], Loss: 0.00033668300602585077
Epoch [186/1000], Loss: 0.08143544942140579
Epoch [187/1000], Loss: 4.589346281136386e-05
Epoch [188/1000], Loss: 0.0001642335409997031
Epoch [189/1000], Loss: 0.01826939545571804
Epoch [190/1000], Loss: 0.003912558313459158
Epoch [191/1000], Loss: 0.002055732300505042
Epoch [192/1000], Loss: 0.018666947260499
Epoch [193/1000], Loss: 0.03998282179236412
Epoch [194/1000], Loss: 0.003459128551185131
Epoch [195/1000], Loss: 0.007804290857166052
Epoch [196/1000], Loss: 0.003949325997382402
Epoch [197/1000], Loss: 0.010333920828998089
Epoch [198/1000], Loss: 0.0025270082987844944
Epoch [199/1000], Loss: 0.00010441386257298291
Epoch [200/1000], Loss: 0.0006989555549807847
Epoch [201/1000], Loss: 0.013403504155576229
Epoch [202/1000], Loss: 3.576142989913933e-05
Epoch [203/1000], Loss: 0.004903531167656183
Epoch [204/1000], Loss: 0.00018069666111841798
Epoch [205/1000], Loss: 5.0900114729302004e-05
Epoch [206/1000], Loss: 0.02559501864016056
Epoch [207/1000], Loss: 0.003082460956647992
Epoch [208/1000], Loss: 1.680833702266682e-05
Epoch [209/1000], Loss: 0.0003366648161318153
Epoch [210/1000], Loss: 0.0070828101597726345
Epoch [211/1000], Loss: 0.052668530493974686
Epoch [212/1000], Loss: 0.0020989973563700914
Epoch [213/1000], Loss: 0.00011998503032373264
Epoch [214/1000], Loss: 0.015271606855094433
Epoch [215/1000], Loss: 0.0049392045475542545
Epoch [216/1000], Loss: 0.00016111477452795953
Epoch [217/1000], Loss: 0.0012649690033867955
Epoch [218/1000], Loss: 4.633116259356029e-05
Epoch [219/1000], Loss: 5.419662920758128e-05
Epoch [220/1000], Loss: 0.0007031368440948427
Epoch [221/1000], Loss: 0.00438720965757966
Epoch [222/1000], Loss: 0.0004590859462041408
Epoch [223/1000], Loss: 0.0001187185916933231
Epoch [224/1000], Loss: 0.00010942292283289135
Epoch [225/1000], Loss: 0.15309756994247437
Epoch [226/1000], Loss: 0.12165316939353943
Epoch [227/1000], Loss: 0.000604152912274003
Epoch [228/1000], Loss: 0.17232732474803925
Epoch [229/1000], Loss: 0.000857457984238863
Epoch [230/1000], Loss: 0.04528741538524628
Epoch [231/1000], Loss: 0.12963519990444183
Epoch [232/1000], Loss: 0.0007794878911226988
Epoch [233/1000], Loss: 0.0003443397581577301
Epoch [234/1000], Loss: 0.0025003214832395315
Epoch [235/1000], Loss: 0.13308213651180267
Epoch [236/1000], Loss: 0.26345351338386536
Epoch [237/1000], Loss: 1.3748668607149739e-05
Epoch [238/1000], Loss: 0.001692633144557476
Epoch [239/1000], Loss: 9.496942766418215e-06
Epoch [240/1000], Loss: 0.00016476225573569536
Epoch [241/1000], Loss: 0.00032190425554290414
Epoch [242/1000], Loss: 0.000348971487255767
Epoch [243/1000], Loss: 0.0007447866373695433
Epoch [244/1000], Loss: 0.00016869565297383815
Epoch [245/1000], Loss: 0.0026510946918278933
Epoch [246/1000], Loss: 0.00025664016720838845
Epoch [247/1000], Loss: 0.0186990424990654
Epoch [248/1000], Loss: 0.005083231721073389
Epoch [249/1000], Loss: 0.1983913779258728
Epoch [250/1000], Loss: 0.011367648839950562
Epoch [251/1000], Loss: 0.11098421365022659
Epoch [252/1000], Loss: 0.0019648137968033552
Epoch [253/1000], Loss: 0.00010401498730061576
Epoch [254/1000], Loss: 0.0012662630761042237
Epoch [255/1000], Loss: 0.0015655405586585402
Epoch [256/1000], Loss: 0.26185038685798645
Epoch [257/1000], Loss: 0.0016495268791913986
Epoch [258/1000], Loss: 0.03976323828101158
Epoch [259/1000], Loss: 0.0018206970999017358
Epoch [260/1000], Loss: 0.0014550498453900218
Epoch [261/1000], Loss: 0.12985791265964508
Epoch [262/1000], Loss: 7.98697965365136e-06
Epoch [263/1000], Loss: 0.02159888856112957
Epoch [264/1000], Loss: 0.011135159991681576
Epoch [265/1000], Loss: 0.00437950249761343
Epoch [266/1000], Loss: 0.0004725938197225332
Epoch [267/1000], Loss: 5.8014816204376984e-06
Epoch [268/1000], Loss: 0.268361359834671
Epoch [269/1000], Loss: 0.004129732493311167
Epoch [270/1000], Loss: 3.3775897918530973e-06
Epoch [271/1000], Loss: 2.2291513232630678e-05
Epoch [272/1000], Loss: 0.0007389441598206758
Epoch [273/1000], Loss: 0.00017219274013768882
Epoch [274/1000], Loss: 1.573549525346607e-05
Epoch [275/1000], Loss: 3.246402047807351e-05
Epoch [276/1000], Loss: 4.927297140966402e-06
Epoch [277/1000], Loss: 0.0006502466858364642
Epoch [278/1000], Loss: 0.9389085173606873
Epoch [279/1000], Loss: 0.0005758660845458508
Epoch [280/1000], Loss: 0.000510109297465533
Epoch [281/1000], Loss: 0.005502698477357626
Epoch [282/1000], Loss: 1.0609550372464582e-05
Epoch [283/1000], Loss: 0.0008327783434651792
Epoch [284/1000], Loss: 0.0007309298380278051
Epoch [285/1000], Loss: 0.0010387097718194127
Epoch [286/1000], Loss: 2.6861018341151066e-05
Epoch [287/1000], Loss: 0.001372645259834826
Epoch [288/1000], Loss: 2.1536856365855783e-05
Epoch [289/1000], Loss: 2.407984902674798e-05
Epoch [290/1000], Loss: 1.4424171240534633e-05
Epoch [291/1000], Loss: 0.00033616137807257473
Epoch [292/1000], Loss: 0.001534531475044787
Epoch [293/1000], Loss: 6.194374873302877e-05
Epoch [294/1000], Loss: 6.862032023491338e-05
Epoch [295/1000], Loss: 0.0016684256261214614
Epoch [296/1000], Loss: 0.002257888438180089
Epoch [297/1000], Loss: 0.0033312449231743813
Epoch [298/1000], Loss: 0.11227668076753616
Epoch [299/1000], Loss: 0.0840858593583107
Epoch [300/1000], Loss: 0.021000059321522713
Epoch [301/1000], Loss: 0.0069240424782037735
Epoch [302/1000], Loss: 0.08934066444635391
Epoch [303/1000], Loss: 5.908537423238158e-05
Epoch [304/1000], Loss: 0.006029652897268534
Epoch [305/1000], Loss: 3.3099695428973064e-05
Epoch [306/1000], Loss: 0.00048349486314691603
Epoch [307/1000], Loss: 7.453806028934196e-05
Epoch [308/1000], Loss: 0.00022191095922607929
Epoch [309/1000], Loss: 0.0024303009267896414
Epoch [310/1000], Loss: 0.0003292943583801389
Epoch [311/1000], Loss: 0.0006432586233131588
Epoch [312/1000], Loss: 3.0199614684534026e-06
Epoch [313/1000], Loss: 0.010395828634500504
Epoch [314/1000], Loss: 3.754940189537592e-05
Epoch [315/1000], Loss: 0.007289662957191467
Epoch [316/1000], Loss: 3.7271787732606754e-05
Epoch [317/1000], Loss: 7.74415020714514e-05
Epoch [318/1000], Loss: 0.010665345937013626
Epoch [319/1000], Loss: 0.0010272881481796503
Epoch [320/1000], Loss: 0.0001286421320401132
Epoch [321/1000], Loss: 3.933896550734062e-06
Epoch [322/1000], Loss: 0.008076244033873081
Epoch [323/1000], Loss: 0.000923442654311657
Epoch [324/1000], Loss: 7.994045154191554e-05
Epoch [325/1000], Loss: 0.00046114236465655267
Epoch [326/1000], Loss: 0.21892844140529633
Epoch [327/1000], Loss: 0.012342195026576519
Epoch [328/1000], Loss: 0.0003089321544393897
Epoch [329/1000], Loss: 0.0015372439520433545
Epoch [330/1000], Loss: 0.0003504924534354359
Epoch [331/1000], Loss: 0.0011787355178967118
Epoch [332/1000], Loss: 0.001839496660977602
Epoch [333/1000], Loss: 0.01655675657093525
Epoch [334/1000], Loss: 0.0030320174992084503
Epoch [335/1000], Loss: 9.440704161534086e-05
Epoch [336/1000], Loss: 0.010311472229659557
Epoch [337/1000], Loss: 0.012767571024596691
Epoch [338/1000], Loss: 5.936153684160672e-05
Epoch [339/1000], Loss: 0.0026790809351950884
Epoch [340/1000], Loss: 0.0004745274782180786
Epoch [341/1000], Loss: 0.0004303473688196391
Epoch [342/1000], Loss: 0.002474934561178088
Epoch [343/1000], Loss: 0.0009375668596476316
Epoch [344/1000], Loss: 0.00491379713639617
Epoch [345/1000], Loss: 7.3114661063300446e-06
Epoch [346/1000], Loss: 0.0006540194153785706
Epoch [347/1000], Loss: 7.136110070860013e-05
Epoch [348/1000], Loss: 0.0002034210629062727
Epoch [349/1000], Loss: 0.002052210969850421
Epoch [350/1000], Loss: 0.02022840455174446
Epoch [351/1000], Loss: 0.011605030857026577
Epoch [352/1000], Loss: 9.15427808649838e-05
Epoch [353/1000], Loss: 0.20685209333896637
Epoch [354/1000], Loss: 9.05103879631497e-05
Epoch [355/1000], Loss: 6.55192052363418e-05
Epoch [356/1000], Loss: 0.08729320764541626
Epoch [357/1000], Loss: 5.077963578514755e-05
Epoch [358/1000], Loss: 7.073050710459938e-06
Epoch [359/1000], Loss: 0.022623715922236443
Epoch [360/1000], Loss: 5.737541141570546e-05
Epoch [361/1000], Loss: 0.00016119102656375617
Epoch [362/1000], Loss: 0.0006912908866070211
Epoch [363/1000], Loss: 0.0006947782239876688
Epoch [364/1000], Loss: 0.00041459998465143144
Epoch [365/1000], Loss: 0.0064354147762060165
Epoch [366/1000], Loss: 1.629167491046246e-05
Epoch [367/1000], Loss: 4.104586332687177e-05
Epoch [368/1000], Loss: 0.0004372446273919195
Epoch [369/1000], Loss: 9.237923222826794e-05
Epoch [370/1000], Loss: 0.19805043935775757
Epoch [371/1000], Loss: 0.00038864664384163916
Epoch [372/1000], Loss: 0.0023833520244807005
Epoch [373/1000], Loss: 8.741964848013595e-06
Epoch [374/1000], Loss: 0.034957095980644226
Epoch [375/1000], Loss: 1.3867732377548236e-05
Epoch [376/1000], Loss: 1.0251890671497677e-05
Epoch [377/1000], Loss: 7.74852651375113e-06
Epoch [378/1000], Loss: 0.00026867075939662755
Epoch [379/1000], Loss: 1.0331464181945194e-06
Epoch [380/1000], Loss: 0.0004906977992504835
Epoch [381/1000], Loss: 0.0003367715689819306
Epoch [382/1000], Loss: 0.0008287276141345501
Epoch [383/1000], Loss: 1.2906352281570435
Epoch [384/1000], Loss: 0.08731762319803238
Epoch [385/1000], Loss: 0.013385293073952198
Epoch [386/1000], Loss: 0.000393064838135615
Epoch [387/1000], Loss: 0.12880836427211761
Epoch [388/1000], Loss: 0.00012768949090968817
Epoch [389/1000], Loss: 0.001460521831177175
Epoch [390/1000], Loss: 0.0006337238592095673
Epoch [391/1000], Loss: 0.00013938006304670125
Traceback (most recent call last):
  File "C:\Users\Administrator\Desktop\CV\lab1\lab.py", line 64, in <module>
    outputs = model(inputs)
              ^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\envs\QMR_CV\Lib\site-packages\torch\nn\modules\module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\envs\QMR_CV\Lib\site-packages\torch\nn\modules\module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\Administrator\Desktop\CV\lab1\lab.py", line 43, in forward
    out = self.fc1(x)
          ^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\envs\QMR_CV\Lib\site-packages\torch\nn\modules\module.py", line 1736, in _wrapped_call_impl
    return self._call_impl(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\envs\QMR_CV\Lib\site-packages\torch\nn\modules\module.py", line 1747, in _call_impl
    return forward_call(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\ProgramData\anaconda3\envs\QMR_CV\Lib\site-packages\torch\nn\modules\linear.py", line 125, in forward
    return F.linear(input, self.weight, self.bias)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
KeyboardInterrupt
^C
(QMR_CV) C:\Users\Administrator\Desktop\CV\lab1>python lab.py
timer 1s
start
IF GPU READY: True
cuda
Epoch [1/20], Loss: 0.557312548160553
Epoch [2/20], Loss: 0.12574650347232819
Epoch [3/20], Loss: 0.07317594438791275
Epoch [4/20], Loss: 0.14396382868289948
Epoch [5/20], Loss: 0.020471513271331787
Epoch [6/20], Loss: 0.027904100716114044
Epoch [7/20], Loss: 0.28319939970970154
Epoch [8/20], Loss: 0.08314955979585648
Epoch [9/20], Loss: 0.042805805802345276
Epoch [10/20], Loss: 0.0068653654307127
Epoch [11/20], Loss: 0.0026914107147604227
Epoch [12/20], Loss: 0.004118998069316149
Epoch [13/20], Loss: 0.005800043698400259
Epoch [14/20], Loss: 0.045344848185777664
Epoch [15/20], Loss: 0.020420856773853302
Epoch [16/20], Loss: 0.004004392307251692
Epoch [17/20], Loss: 0.001819909899495542
Epoch [18/20], Loss: 0.00039461880805902183
Epoch [19/20], Loss: 0.02185303531587124
Epoch [20/20], Loss: 0.003414002014324069
Accuracy of the model on the test set: 97.5%

(QMR_CV) C:\Users\Administrator\Desktop\CV\lab1>python lab.py
timer 1s
start
IF GPU READY: True
cuda
Epoch [1/20], Loss: 0.9791129231452942
Epoch [2/20], Loss: 0.7095702886581421
Epoch [3/20], Loss: 0.5840241312980652
Epoch [4/20], Loss: 0.5037593841552734
Epoch [5/20], Loss: 0.2824609577655792
Epoch [6/20], Loss: 0.2636409103870392
Epoch [7/20], Loss: 0.24163971841335297
Epoch [8/20], Loss: 0.17913535237312317
Epoch [9/20], Loss: 0.13728125393390656
Epoch [10/20], Loss: 0.20350486040115356
Epoch [11/20], Loss: 0.09261365234851837
Epoch [12/20], Loss: 0.12185964733362198
Epoch [13/20], Loss: 0.08304198831319809
Epoch [14/20], Loss: 0.1370508223772049
Epoch [15/20], Loss: 0.0849018469452858
Epoch [16/20], Loss: 0.14263495802879333
Epoch [17/20], Loss: 0.06403787434101105
Epoch [18/20], Loss: 0.14140333235263824
Epoch [19/20], Loss: 0.09858153015375137
Epoch [20/20], Loss: 0.03798972815275192
Accuracy of the model on the test set: 98.75%

(QMR_CV) C:\Users\Administrator\Desktop\CV\lab1>python lab.py
timer 1s
start
IF GPU READY: True
cuda
Epoch [1/40], Loss: 0.6416040062904358
Epoch [2/40], Loss: 0.18591651320457458
Epoch [3/40], Loss: 0.18794754147529602
Epoch [4/40], Loss: 0.1301601082086563
Epoch [5/40], Loss: 0.06074943020939827
Epoch [6/40], Loss: 0.03607552871108055
Epoch [7/40], Loss: 0.03371790051460266
Epoch [8/40], Loss: 0.20467939972877502
Epoch [9/40], Loss: 0.010175635106861591
Epoch [10/40], Loss: 0.3040103614330292
Epoch [11/40], Loss: 0.017325716093182564
Epoch [12/40], Loss: 0.01914740726351738
Epoch [13/40], Loss: 0.02451387420296669
Epoch [14/40], Loss: 0.06332016736268997
Epoch [15/40], Loss: 0.07292649894952774
Epoch [16/40], Loss: 0.05446407198905945
Epoch [17/40], Loss: 0.046974748373031616
Epoch [18/40], Loss: 0.02076483890414238
Epoch [19/40], Loss: 0.010959812439978123
Epoch [20/40], Loss: 0.00461134547367692
Epoch [21/40], Loss: 0.03750063106417656
Epoch [22/40], Loss: 0.005091528873890638
Epoch [23/40], Loss: 0.01347583532333374
Epoch [24/40], Loss: 0.021034391596913338
Epoch [25/40], Loss: 0.010969216004014015
Epoch [26/40], Loss: 0.026521431282162666
Epoch [27/40], Loss: 0.07454375177621841
Epoch [28/40], Loss: 0.009928323328495026
Epoch [29/40], Loss: 0.009229038842022419
Epoch [30/40], Loss: 0.03317379578948021
Epoch [31/40], Loss: 0.001816537813283503
Epoch [32/40], Loss: 0.04075228422880173
Epoch [33/40], Loss: 0.013107312843203545
Epoch [34/40], Loss: 0.11685951054096222
Epoch [35/40], Loss: 0.01647154614329338
Epoch [36/40], Loss: 0.0058609056286513805
Epoch [37/40], Loss: 0.009608314372599125
Epoch [38/40], Loss: 0.03647827357053757
Epoch [39/40], Loss: 0.02611800841987133
Epoch [40/40], Loss: 0.0005605685873888433
Accuracy of the model on the test set: 98.25%


Microsoft Windows [版本 10.0.19045.4957]
(c) Microsoft Corporation。保留所有权利。

(QMR) C:\Users\Administrator\Desktop\HUST-CV>C:/ProgramData/anaconda3/envs/QMR/python.exe c:/Users/Administrator/Desktop/HUST-CV/mlp/lab_qmr.py
timer 5s
True
start
Epoch [10/100], Loss: 1.0775188207626343
Epoch [20/100], Loss: 1.0198582410812378
Epoch [30/100], Loss: 0.9785978198051453
Epoch [40/100], Loss: 0.940784215927124 
Epoch [50/100], Loss: 0.9048259854316711
Epoch [60/100], Loss: 0.8703478574752808
Epoch [70/100], Loss: 0.8372302651405334
Epoch [80/100], Loss: 0.8055086731910706
Epoch [90/100], Loss: 0.7753512263298035
Epoch [100/100], Loss: 0.7467939853668213
Accuracy of the model on the test set: 73.33333333333333%

(QMR) C:\Users\Administrator\Desktop\HUST-CV>C:/ProgramData/anaconda3/envs/QMR/python.exe c:/Users/Administrator/Desktop/HUST-CV/mlp/lab_qmr.py
timer 5s
True
start
Epoch [10/500], Loss: 0.9952073693275452
Epoch [20/500], Loss: 0.9552009105682373
Epoch [30/500], Loss: 0.9172471165657043
Epoch [40/500], Loss: 0.8776795864105225
Epoch [50/500], Loss: 0.8393732905387878
Epoch [60/500], Loss: 0.8076473474502563
Epoch [70/500], Loss: 0.7775803208351135
Epoch [80/500], Loss: 0.7483299970626831
Epoch [90/500], Loss: 0.7203820943832397
Epoch [100/500], Loss: 0.694040834903717
Epoch [110/500], Loss: 0.6697395443916321
Epoch [120/500], Loss: 0.6477349996566772
Epoch [130/500], Loss: 0.6274657845497131
Epoch [140/500], Loss: 0.608512282371521
Epoch [150/500], Loss: 0.5908138751983643
Epoch [160/500], Loss: 0.5743315815925598
Epoch [170/500], Loss: 0.559145987033844
Epoch [180/500], Loss: 0.5450966358184814
Epoch [190/500], Loss: 0.5319651961326599
Epoch [200/500], Loss: 0.5197835564613342
Epoch [210/500], Loss: 0.5083927512168884
Epoch [220/500], Loss: 0.49772199988365173
Epoch [230/500], Loss: 0.4876689612865448
Epoch [240/500], Loss: 0.4781962037086487
Epoch [250/500], Loss: 0.46924394369125366
Epoch [260/500], Loss: 0.4607383608818054
Epoch [270/500], Loss: 0.45263543725013733
Epoch [280/500], Loss: 0.44487932324409485
Epoch [290/500], Loss: 0.43745434284210205
Epoch [300/500], Loss: 0.4303257167339325
Epoch [310/500], Loss: 0.42346206307411194
Epoch [320/500], Loss: 0.41684019565582275
Epoch [330/500], Loss: 0.4104464650154114
Epoch [340/500], Loss: 0.4042549729347229
Epoch [350/500], Loss: 0.39825204014778137
Epoch [360/500], Loss: 0.3924231231212616
Epoch [370/500], Loss: 0.3867553770542145
Epoch [380/500], Loss: 0.38123512268066406
Epoch [390/500], Loss: 0.3758520185947418
Epoch [400/500], Loss: 0.3705946207046509
Epoch [410/500], Loss: 0.36545705795288086
Epoch [420/500], Loss: 0.36042943596839905
Epoch [430/500], Loss: 0.3555046319961548
Epoch [440/500], Loss: 0.3506809175014496
Epoch [450/500], Loss: 0.34595391154289246
Epoch [460/500], Loss: 0.34132179617881775
Epoch [470/500], Loss: 0.336782306432724
Epoch [480/500], Loss: 0.3323290944099426
Epoch [490/500], Loss: 0.3279631733894348
Epoch [500/500], Loss: 0.3236788511276245
Accuracy of the model on the test set: 100.0%

(QMR) C:\Users\Administrator\Desktop\HUST-CV>C:/ProgramData/anaconda3/envs/QMR/python.exe c:/Users/Administrator/Desktop/HUST-CV/mlp/lab_qmr.py
timer 5s
True
start
Epoch [10/500], Loss: 0.9914829134941101
Epoch [20/500], Loss: 0.7175624966621399 
Epoch [30/500], Loss: 0.5416432023048401 
Epoch [40/500], Loss: 0.44182807207107544
Epoch [50/500], Loss: 0.3729058504104614 
Epoch [60/500], Loss: 0.31072142720222473
Epoch [70/500], Loss: 0.25461503863334656
Epoch [80/500], Loss: 0.20773328840732574 
Epoch [90/500], Loss: 0.17133553326129913 
Epoch [100/500], Loss: 0.14437882602214813
Epoch [110/500], Loss: 0.12482898682355881
Epoch [120/500], Loss: 0.11068034917116165
Epoch [130/500], Loss: 0.10029398649930954
Epoch [140/500], Loss: 0.09250326454639435
Epoch [150/500], Loss: 0.08650895953178406
Epoch [160/500], Loss: 0.08178768306970596
Epoch [170/500], Loss: 0.0780133455991745 
Epoch [180/500], Loss: 0.07493262737989426
Epoch [190/500], Loss: 0.07238556444644928
Epoch [200/500], Loss: 0.07025011628866196
Epoch [210/500], Loss: 0.06843945384025574
Epoch [220/500], Loss: 0.06688587367534637
Epoch [230/500], Loss: 0.06554143875837326
Epoch [240/500], Loss: 0.0643678605556488
Epoch [250/500], Loss: 0.06333579868078232
Epoch [260/500], Loss: 0.06242256239056587
Epoch [270/500], Loss: 0.061608873307704926
Epoch [280/500], Loss: 0.06087930127978325
Epoch [290/500], Loss: 0.06022115796804428
Epoch [300/500], Loss: 0.05962417647242546
Epoch [310/500], Loss: 0.0590803287923336
Epoch [320/500], Loss: 0.058582425117492676
Epoch [330/500], Loss: 0.05812462419271469
Epoch [340/500], Loss: 0.05770183727145195
Epoch [350/500], Loss: 0.05730974301695824
Epoch [360/500], Loss: 0.056944798678159714
Epoch [370/500], Loss: 0.05660385638475418
Epoch [380/500], Loss: 0.056284163147211075
Epoch [390/500], Loss: 0.05598337575793266
Epoch [400/500], Loss: 0.05569960176944733
Epoch [410/500], Loss: 0.0554310567677021
Epoch [420/500], Loss: 0.05517604574561119
Epoch [430/500], Loss: 0.05493338778614998
Epoch [440/500], Loss: 0.05470191314816475
Epoch [450/500], Loss: 0.05448050796985626
Epoch [460/500], Loss: 0.054268285632133484
Epoch [470/500], Loss: 0.05406449735164642
Epoch [480/500], Loss: 0.053868409246206284
Epoch [490/500], Loss: 0.05367942154407501
Epoch [500/500], Loss: 0.05349693074822426
Accuracy of the model on the test set: 100.0%

(QMR) C:\Users\Administrator\Desktop\HUST-CV>C:/ProgramData/anaconda3/envs/QMR/python.exe c:/Users/Administrator/Desktop/HUST-CV/mlp/lab_qmr.py
timer 5s
True
start
Epoch [10/500], Loss: 0.39503586292266846
Epoch [20/500], Loss: 0.2497820258140564
Epoch [30/500], Loss: 0.16009339690208435
Epoch [40/500], Loss: 0.11280631273984909
Epoch [50/500], Loss: 0.09077070653438568
Epoch [60/500], Loss: 0.07888307422399521
Epoch [70/500], Loss: 0.07219497114419937
Epoch [80/500], Loss: 0.06793829798698425
Epoch [90/500], Loss: 0.06499739736318588
Epoch [100/500], Loss: 0.06284227967262268
Epoch [110/500], Loss: 0.06118529662489891
Epoch [120/500], Loss: 0.05986495688557625
Epoch [130/500], Loss: 0.05877350643277168
Epoch [140/500], Loss: 0.057857025414705276
Epoch [150/500], Loss: 0.05707240104675293
Epoch [160/500], Loss: 0.05637575313448906
Epoch [170/500], Loss: 0.05574914440512657
Epoch [180/500], Loss: 0.05517822876572609
Epoch [190/500], Loss: 0.05463403835892677
Epoch [200/500], Loss: 0.054163046181201935
Epoch [210/500], Loss: 0.053704507648944855
Epoch [220/500], Loss: 0.053306497633457184
Epoch [230/500], Loss: 0.05288754776120186
Epoch [240/500], Loss: 0.052490487694740295
Epoch [250/500], Loss: 0.05205685645341873
Epoch [260/500], Loss: 0.051743511110544205
Epoch [270/500], Loss: 0.051334403455257416
Epoch [280/500], Loss: 0.05103510618209839
Epoch [290/500], Loss: 0.050664130598306656
Epoch [300/500], Loss: 0.050373367965221405
Epoch [310/500], Loss: 0.050046827644109726
Epoch [320/500], Loss: 0.04991217330098152
Epoch [330/500], Loss: 0.04966503754258156
Epoch [340/500], Loss: 0.049409616738557816
Epoch [350/500], Loss: 0.0491955503821373
Epoch [360/500], Loss: 0.048967890441417694
Epoch [370/500], Loss: 0.048761289566755295
Epoch [380/500], Loss: 0.048740167170763016
Epoch [210/500], Loss: 0.053704507648944855
Epoch [220/500], Loss: 0.053306497633457184
Epoch [230/500], Loss: 0.05288754776120186
Epoch [240/500], Loss: 0.052490487694740295
Epoch [250/500], Loss: 0.05205685645341873
Epoch [260/500], Loss: 0.051743511110544205
Epoch [270/500], Loss: 0.051334403455257416
Epoch [280/500], Loss: 0.05103510618209839
Epoch [290/500], Loss: 0.050664130598306656
Epoch [300/500], Loss: 0.050373367965221405
Epoch [310/500], Loss: 0.050046827644109726
Epoch [320/500], Loss: 0.04991217330098152
Epoch [330/500], Loss: 0.04966503754258156
Epoch [340/500], Loss: 0.049409616738557816
Epoch [350/500], Loss: 0.0491955503821373
Epoch [360/500], Loss: 0.048967890441417694
Epoch [370/500], Loss: 0.048761289566755295
Epoch [380/500], Loss: 0.048740167170763016
Epoch [230/500], Loss: 0.05288754776120186
Epoch [240/500], Loss: 0.052490487694740295
Epoch [250/500], Loss: 0.05205685645341873
Epoch [260/500], Loss: 0.051743511110544205
Epoch [270/500], Loss: 0.051334403455257416
Epoch [280/500], Loss: 0.05103510618209839
Epoch [290/500], Loss: 0.050664130598306656
Epoch [300/500], Loss: 0.050373367965221405
Epoch [310/500], Loss: 0.050046827644109726
Epoch [320/500], Loss: 0.04991217330098152
Epoch [330/500], Loss: 0.04966503754258156
Epoch [340/500], Loss: 0.049409616738557816
Epoch [350/500], Loss: 0.0491955503821373
Epoch [360/500], Loss: 0.048967890441417694
Epoch [370/500], Loss: 0.048761289566755295
Epoch [380/500], Loss: 0.048740167170763016
Epoch [270/500], Loss: 0.051334403455257416
Epoch [280/500], Loss: 0.05103510618209839
Epoch [290/500], Loss: 0.050664130598306656
Epoch [300/500], Loss: 0.050373367965221405
Epoch [310/500], Loss: 0.050046827644109726
Epoch [320/500], Loss: 0.04991217330098152
Epoch [330/500], Loss: 0.04966503754258156
Epoch [340/500], Loss: 0.049409616738557816
Epoch [350/500], Loss: 0.0491955503821373
Epoch [360/500], Loss: 0.048967890441417694
Epoch [370/500], Loss: 0.048761289566755295
Epoch [380/500], Loss: 0.048740167170763016
Epoch [290/500], Loss: 0.050664130598306656
Epoch [300/500], Loss: 0.050373367965221405
Epoch [310/500], Loss: 0.050046827644109726
Epoch [320/500], Loss: 0.04991217330098152
Epoch [330/500], Loss: 0.04966503754258156
Epoch [340/500], Loss: 0.049409616738557816
Epoch [350/500], Loss: 0.0491955503821373
Epoch [360/500], Loss: 0.048967890441417694
Epoch [370/500], Loss: 0.048761289566755295
Epoch [380/500], Loss: 0.048740167170763016
Epoch [320/500], Loss: 0.04991217330098152
Epoch [330/500], Loss: 0.04966503754258156
Epoch [340/500], Loss: 0.049409616738557816
Epoch [350/500], Loss: 0.0491955503821373
Epoch [360/500], Loss: 0.048967890441417694
Epoch [370/500], Loss: 0.048761289566755295
Epoch [380/500], Loss: 0.048740167170763016
Epoch [330/500], Loss: 0.04966503754258156
Epoch [340/500], Loss: 0.049409616738557816
Epoch [350/500], Loss: 0.0491955503821373
Epoch [360/500], Loss: 0.048967890441417694
Epoch [370/500], Loss: 0.048761289566755295
Epoch [380/500], Loss: 0.048740167170763016
Epoch [340/500], Loss: 0.049409616738557816
Epoch [350/500], Loss: 0.0491955503821373
Epoch [360/500], Loss: 0.048967890441417694
Epoch [370/500], Loss: 0.048761289566755295
Epoch [380/500], Loss: 0.048740167170763016
Epoch [390/500], Loss: 0.04866250231862068
Epoch [400/500], Loss: 0.04825977608561516
Epoch [350/500], Loss: 0.0491955503821373
Epoch [360/500], Loss: 0.048967890441417694
Epoch [370/500], Loss: 0.048761289566755295
Epoch [380/500], Loss: 0.048740167170763016
Epoch [390/500], Loss: 0.04866250231862068
Epoch [400/500], Loss: 0.04825977608561516
Epoch [370/500], Loss: 0.048761289566755295
Epoch [380/500], Loss: 0.048740167170763016
Epoch [390/500], Loss: 0.04866250231862068
Epoch [400/500], Loss: 0.04825977608561516
Epoch [390/500], Loss: 0.04866250231862068
Epoch [400/500], Loss: 0.04825977608561516
Epoch [410/500], Loss: 0.048167403787374496
Epoch [410/500], Loss: 0.048167403787374496
Epoch [420/500], Loss: 0.0479755625128746
Epoch [420/500], Loss: 0.0479755625128746
Epoch [430/500], Loss: 0.047827064990997314
Epoch [430/500], Loss: 0.047827064990997314
Epoch [440/500], Loss: 0.04762757942080498
Epoch [440/500], Loss: 0.04762757942080498
Epoch [450/500], Loss: 0.047392867505550385
Epoch [450/500], Loss: 0.047392867505550385
Epoch [460/500], Loss: 0.047544214874506
Epoch [470/500], Loss: 0.047536030411720276
Epoch [480/500], Loss: 0.047206539660692215
Epoch [490/500], Loss: 0.04689197987318039
Epoch [490/500], Loss: 0.04689197987318039
Epoch [500/500], Loss: 0.046919457614421844
Epoch [490/500], Loss: 0.04689197987318039
Epoch [500/500], Loss: 0.046919457614421844
Accuracy of the model on the test set: 100.0%
Epoch [490/500], Loss: 0.04689197987318039
Epoch [500/500], Loss: 0.046919457614421844
Accuracy of the model on the test set: 100.0%
Epoch [490/500], Loss: 0.04689197987318039
Epoch [500/500], Loss: 0.046919457614421844
Accuracy of the model on the test set: 100.0%
Epoch [500/500], Loss: 0.046919457614421844
Accuracy of the model on the test set: 100.0%



(QMR) C:\Users\Administrator\Desktop\HUST-CV>C:/ProgramData/anaconda3/envs/QMR/python.exe c:/Users/Administrator/Desktop/HUST-CV/mlp/lab_qmr.py
timer 5s
True
start
Epoch [10/500], Loss: 0.40613603591918945
Epoch [20/500], Loss: 0.2734881043434143
Epoch [30/500], Loss: 0.17064543068408966
Epoch [40/500], Loss: 0.12372754514217377
Epoch [50/500], Loss: 0.10121509432792664
Epoch [60/500], Loss: 0.0884091928601265
Epoch [70/500], Loss: 0.08025357872247696
Epoch [80/500], Loss: 0.0747915729880333
Epoch [90/500], Loss: 0.07096278667449951
Epoch [100/500], Loss: 0.06813176721334457
Epoch [110/500], Loss: 0.06595390290021896
Epoch [120/500], Loss: 0.06424631178379059
Epoch [130/500], Loss: 0.06286691874265671
Epoch [140/500], Loss: 0.061728548258543015
Epoch [150/500], Loss: 0.06076798960566521
Epoch [160/500], Loss: 0.05994205176830292
Epoch [170/500], Loss: 0.05921877175569534
Epoch [180/500], Loss: 0.05857548862695694
Epoch [190/500], Loss: 0.05799518898129463
Epoch [200/500], Loss: 0.057465385645627975
Epoch [210/500], Loss: 0.056975506246089935
Epoch [220/500], Loss: 0.05651869997382164
Epoch [230/500], Loss: 0.05608920007944107
Epoch [240/500], Loss: 0.05568242818117142
Epoch [250/500], Loss: 0.0552949383854866
Epoch [260/500], Loss: 0.05492419749498367
Epoch [270/500], Loss: 0.05456777662038803
Epoch [280/500], Loss: 0.05422418564558029
Epoch [290/500], Loss: 0.053892310708761215
Epoch [300/500], Loss: 0.05357086658477783
Epoch [310/500], Loss: 0.05325927585363388
Epoch [320/500], Loss: 0.052957016974687576
Epoch [330/500], Loss: 0.05266379565000534
Epoch [340/500], Loss: 0.05237921327352524
Epoch [350/500], Loss: 0.05210304260253906
Epoch [360/500], Loss: 0.05183504894375801
Epoch [370/500], Loss: 0.05157546326518059
Epoch [380/500], Loss: 0.051324132829904556
Epoch [390/500], Loss: 0.051081057637929916
Epoch [400/500], Loss: 0.050846245139837265
Epoch [410/500], Loss: 0.05061950907111168
Epoch [420/500], Loss: 0.05040103942155838
Epoch [430/500], Loss: 0.05019082874059677
Epoch [440/500], Loss: 0.049988847225904465
Epoch [450/500], Loss: 0.04979507252573967
Epoch [460/500], Loss: 0.04960956051945686
Epoch [470/500], Loss: 0.04943214729428291
Epoch [480/500], Loss: 0.049262840300798416
Epoch [490/500], Loss: 0.049101490527391434
Epoch [500/500], Loss: 0.048948101699352264
Accuracy of the model on the test set: 100.0%

(QMR) C:\Users\Administrator\Desktop\HUST-CV>C:/ProgramData/anaconda3/envs/QMR/python.exe c:/Users/Administrator/Desktop/HUST-CV/mlp/lab_zj.py
timer 1s
start
IF GPU READY: True
cuda
Epoch [1/40], Loss: 0.5588844418525696
Epoch [2/40], Loss: 0.278902143239975
Epoch [3/40], Loss: 0.15800787508487701
Epoch [4/40], Loss: 0.22041693329811096
Epoch [5/40], Loss: 0.14167048037052155
Epoch [6/40], Loss: 0.04554285481572151
Epoch [7/40], Loss: 0.02547261118888855
Epoch [8/40], Loss: 0.08743282407522202
Epoch [9/40], Loss: 0.09186577796936035
Epoch [10/40], Loss: 0.20301704108715057
Epoch [11/40], Loss: 0.0334421806037426
Epoch [12/40], Loss: 0.014968009665608406
Epoch [13/40], Loss: 0.021558301523327827
Epoch [14/40], Loss: 0.03619084134697914
Epoch [15/40], Loss: 0.019526749849319458
Epoch [16/40], Loss: 0.012373151257634163
Epoch [17/40], Loss: 0.057685546576976776
Epoch [18/40], Loss: 0.01944851502776146
Epoch [19/40], Loss: 0.049950700253248215
Epoch [20/40], Loss: 0.024848749861121178
Epoch [21/40], Loss: 0.056381531059741974
Epoch [22/40], Loss: 0.04665735736489296
Epoch [22/40], Loss: 0.04665735736489296
Epoch [23/40], Loss: 0.09200024604797363
Epoch [24/40], Loss: 0.34380486607551575
Epoch [25/40], Loss: 0.025220928713679314
Epoch [26/40], Loss: 0.012780067510902882
Epoch [27/40], Loss: 0.01380558218806982
Epoch [28/40], Loss: 0.04143129661679268
Epoch [29/40], Loss: 0.03764582797884941
Epoch [30/40], Loss: 0.005771037191152573
Epoch [31/40], Loss: 0.07503945380449295
Epoch [32/40], Loss: 0.010802986100316048
Epoch [33/40], Loss: 0.035946644842624664
Epoch [34/40], Loss: 0.2908441722393036
Epoch [35/40], Loss: 0.005733132362365723
Epoch [22/40], Loss: 0.04665735736489296
Epoch [23/40], Loss: 0.09200024604797363
Epoch [24/40], Loss: 0.34380486607551575
Epoch [25/40], Loss: 0.025220928713679314
Epoch [26/40], Loss: 0.012780067510902882
Epoch [27/40], Loss: 0.01380558218806982
Epoch [28/40], Loss: 0.04143129661679268
Epoch [29/40], Loss: 0.03764582797884941
Epoch [30/40], Loss: 0.005771037191152573
Epoch [31/40], Loss: 0.07503945380449295
Epoch [32/40], Loss: 0.010802986100316048
Epoch [33/40], Loss: 0.035946644842624664
Epoch [34/40], Loss: 0.2908441722393036
Epoch [22/40], Loss: 0.04665735736489296
Epoch [23/40], Loss: 0.09200024604797363
Epoch [24/40], Loss: 0.34380486607551575
Epoch [25/40], Loss: 0.025220928713679314
Epoch [26/40], Loss: 0.012780067510902882
Epoch [27/40], Loss: 0.01380558218806982
Epoch [28/40], Loss: 0.04143129661679268
Epoch [29/40], Loss: 0.03764582797884941
Epoch [30/40], Loss: 0.005771037191152573
Epoch [31/40], Loss: 0.07503945380449295
Epoch [32/40], Loss: 0.010802986100316048
Epoch [33/40], Loss: 0.035946644842624664
Epoch [22/40], Loss: 0.04665735736489296
Epoch [23/40], Loss: 0.09200024604797363
Epoch [24/40], Loss: 0.34380486607551575
Epoch [25/40], Loss: 0.025220928713679314
Epoch [26/40], Loss: 0.012780067510902882
Epoch [27/40], Loss: 0.01380558218806982
Epoch [28/40], Loss: 0.04143129661679268
Epoch [29/40], Loss: 0.03764582797884941
Epoch [30/40], Loss: 0.005771037191152573
Epoch [31/40], Loss: 0.07503945380449295
Epoch [22/40], Loss: 0.04665735736489296
Epoch [23/40], Loss: 0.09200024604797363
Epoch [24/40], Loss: 0.34380486607551575
Epoch [25/40], Loss: 0.025220928713679314
Epoch [26/40], Loss: 0.012780067510902882
Epoch [27/40], Loss: 0.01380558218806982
Epoch [28/40], Loss: 0.04143129661679268
Epoch [29/40], Loss: 0.03764582797884941
Epoch [22/40], Loss: 0.04665735736489296
Epoch [23/40], Loss: 0.09200024604797363
Epoch [24/40], Loss: 0.34380486607551575
Epoch [25/40], Loss: 0.025220928713679314
Epoch [26/40], Loss: 0.012780067510902882
Epoch [27/40], Loss: 0.01380558218806982
Epoch [28/40], Loss: 0.04143129661679268
Epoch [22/40], Loss: 0.04665735736489296
Epoch [23/40], Loss: 0.09200024604797363
Epoch [24/40], Loss: 0.34380486607551575
Epoch [25/40], Loss: 0.025220928713679314
Epoch [26/40], Loss: 0.012780067510902882
Epoch [27/40], Loss: 0.01380558218806982
Epoch [28/40], Loss: 0.04143129661679268
Epoch [22/40], Loss: 0.04665735736489296
Epoch [23/40], Loss: 0.09200024604797363
Epoch [24/40], Loss: 0.34380486607551575
Epoch [25/40], Loss: 0.025220928713679314
Epoch [26/40], Loss: 0.012780067510902882
Epoch [27/40], Loss: 0.01380558218806982
Epoch [22/40], Loss: 0.04665735736489296
Epoch [23/40], Loss: 0.09200024604797363
Epoch [24/40], Loss: 0.34380486607551575
Epoch [25/40], Loss: 0.025220928713679314
Epoch [26/40], Loss: 0.012780067510902882
Epoch [27/40], Loss: 0.01380558218806982
Epoch [28/40], Loss: 0.04143129661679268
Epoch [24/40], Loss: 0.34380486607551575
Epoch [25/40], Loss: 0.025220928713679314
Epoch [26/40], Loss: 0.012780067510902882
Epoch [27/40], Loss: 0.01380558218806982
Epoch [28/40], Loss: 0.04143129661679268
Epoch [29/40], Loss: 0.03764582797884941
Epoch [26/40], Loss: 0.012780067510902882
Epoch [27/40], Loss: 0.01380558218806982
Epoch [28/40], Loss: 0.04143129661679268
Epoch [29/40], Loss: 0.03764582797884941
Epoch [28/40], Loss: 0.04143129661679268
Epoch [29/40], Loss: 0.03764582797884941
Epoch [30/40], Loss: 0.005771037191152573
Epoch [31/40], Loss: 0.07503945380449295
Epoch [30/40], Loss: 0.005771037191152573
Epoch [31/40], Loss: 0.07503945380449295
Epoch [31/40], Loss: 0.07503945380449295
Epoch [32/40], Loss: 0.010802986100316048
Epoch [32/40], Loss: 0.010802986100316048
Epoch [33/40], Loss: 0.035946644842624664
Epoch [34/40], Loss: 0.2908441722393036
Epoch [35/40], Loss: 0.005733132362365723
Epoch [36/40], Loss: 0.005205451976507902
Epoch [37/40], Loss: 0.30138617753982544
Epoch [38/40], Loss: 0.0226068627089262
Epoch [39/40], Loss: 0.06481918692588806
Epoch [40/40], Loss: 0.025820046663284302
Accuracy of the model on the test set: 99.25%



(QMR) C:\Users\Administrator\Desktop\HUST-CV>C:/ProgramData/anaconda3/envs/QMR/python.exe c:/Users/Administrator/Desktop/HUST-CV/mlp/lab_qmr.py
Epoch [1/50], Loss: 0.6175249814987183
Epoch [2/50], Loss: 0.28344786167144775
Epoch [3/50], Loss: 0.20418767631053925
Epoch [4/50], Loss: 0.05212385207414627
Epoch [5/50], Loss: 0.11969135701656342
Epoch [6/50], Loss: 0.2525535225868225
Epoch [7/50], Loss: 0.06440537422895432
Epoch [8/50], Loss: 0.2804426848888397
Epoch [9/50], Loss: 0.02840925008058548
Epoch [10/50], Loss: 0.09277036786079407
Epoch [11/50], Loss: 0.024386165663599968
Epoch [12/50], Loss: 0.05743253976106644
Epoch [13/50], Loss: 0.18760457634925842
Epoch [14/50], Loss: 0.023716162890195847
Epoch [15/50], Loss: 0.05092375725507736
Epoch [16/50], Loss: 0.040567271411418915
Epoch [17/50], Loss: 0.028316456824541092
Epoch [18/50], Loss: 0.01605129800736904
Epoch [19/50], Loss: 0.007678631227463484
Epoch [20/50], Loss: 0.0077797845005989075
Epoch [21/50], Loss: 0.00937514565885067
Epoch [22/50], Loss: 0.013208938762545586
Epoch [23/50], Loss: 0.021717485040426254
Epoch [24/50], Loss: 0.020246807485818863
Epoch [25/50], Loss: 0.015356731601059437
Epoch [26/50], Loss: 0.001109429053030908
Epoch [27/50], Loss: 0.001952865975908935
Epoch [28/50], Loss: 0.016752146184444427
Epoch [29/50], Loss: 0.01112927682697773
Epoch [30/50], Loss: 0.008316252380609512
Epoch [31/50], Loss: 0.002008001320064068
Epoch [32/50], Loss: 0.0032218487467616796
Epoch [31/50], Loss: 0.002008001320064068
Epoch [32/50], Loss: 0.0032218487467616796
Epoch [33/50], Loss: 0.047200676053762436
Epoch [32/50], Loss: 0.0032218487467616796
Epoch [33/50], Loss: 0.047200676053762436
Epoch [33/50], Loss: 0.047200676053762436
Epoch [34/50], Loss: 0.0021305764093995094
Epoch [34/50], Loss: 0.0021305764093995094
Epoch [35/50], Loss: 0.1991073489189148
Epoch [35/50], Loss: 0.1991073489189148
Epoch [36/50], Loss: 0.008995939046144485
Epoch [36/50], Loss: 0.008995939046144485
Epoch [37/50], Loss: 0.0021136021241545677
Epoch [37/50], Loss: 0.0021136021241545677
Epoch [38/50], Loss: 0.09691118448972702
Epoch [38/50], Loss: 0.09691118448972702
Epoch [39/50], Loss: 0.03249041736125946
Epoch [39/50], Loss: 0.03249041736125946
Epoch [40/50], Loss: 0.005988710559904575
Epoch [40/50], Loss: 0.005988710559904575
Epoch [41/50], Loss: 0.00011567101319087669
Epoch [41/50], Loss: 0.00011567101319087669
Epoch [42/50], Loss: 0.053985558450222015
Epoch [42/50], Loss: 0.053985558450222015
Epoch [43/50], Loss: 0.0020404199603945017
Epoch [43/50], Loss: 0.0020404199603945017
Epoch [44/50], Loss: 0.06406153738498688
Epoch [45/50], Loss: 0.022949058562517166
Epoch [46/50], Loss: 0.0344877764582634
Epoch [47/50], Loss: 0.0029620961286127567
Epoch [48/50], Loss: 0.008034047670662403
Epoch [49/50], Loss: 0.020617812871932983
Epoch [50/50], Loss: 0.004275118932127953
Accuracy on the test set: 98.25%



(QMR) C:\Users\Administrator\Desktop\HUST-CV>C:/ProgramData/anaconda3/envs/QMR/python.exe c:/Users/Administrator/Desktop/HUST-CV/mlp/lab_qmr.py
Epoch [1/50], Loss: 1.164469599723816
Epoch [2/50], Loss: 0.882821798324585
Epoch [3/50], Loss: 0.7311240434646606
Epoch [4/50], Loss: 0.47875627875328064
Epoch [5/50], Loss: 0.4131719470024109
Epoch [6/50], Loss: 0.34656235575675964
Epoch [7/50], Loss: 0.22235311567783356
Epoch [8/50], Loss: 0.2663098871707916
Epoch [9/50], Loss: 0.1104564443230629
Epoch [10/50], Loss: 0.0834067314863205
Epoch [11/50], Loss: 0.18049687147140503
Epoch [12/50], Loss: 0.07799291610717773
Epoch [13/50], Loss: 0.07541079819202423
Epoch [14/50], Loss: 0.1495932936668396
Epoch [15/50], Loss: 0.07978703081607819
Epoch [16/50], Loss: 0.03367581591010094
Epoch [17/50], Loss: 0.16896313428878784
Epoch [18/50], Loss: 0.04448587819933891
Epoch [19/50], Loss: 0.2074892818927765
Epoch [20/50], Loss: 0.168535515666008
Epoch [21/50], Loss: 0.021987607702612877
Epoch [22/50], Loss: 0.05562925338745117
Epoch [23/50], Loss: 0.13920406997203827
Epoch [24/50], Loss: 0.04989982023835182
Epoch [25/50], Loss: 0.13263589143753052
Epoch [26/50], Loss: 0.05373396724462509
Epoch [27/50], Loss: 0.061677370220422745
Epoch [28/50], Loss: 0.04570583626627922
Epoch [29/50], Loss: 0.03979906812310219
Epoch [30/50], Loss: 0.013671818189322948
Epoch [31/50], Loss: 0.1315048336982727
Epoch [32/50], Loss: 0.15564940869808197
Epoch [33/50], Loss: 0.010624285787343979
Epoch [34/50], Loss: 0.23594997823238373
Epoch [35/50], Loss: 0.08528447151184082
Epoch [36/50], Loss: 0.008340059779584408
Epoch [37/50], Loss: 0.015166264958679676
Epoch [38/50], Loss: 0.014766950160264969
Epoch [39/50], Loss: 0.05420568957924843
Epoch [40/50], Loss: 0.012584601528942585
Epoch [41/50], Loss: 0.02595026046037674
Epoch [42/50], Loss: 0.024933388456702232
Epoch [43/50], Loss: 0.017879148945212364
Epoch [44/50], Loss: 0.007350316736847162
Epoch [44/50], Loss: 0.007350316736847162
Epoch [45/50], Loss: 0.010187110863626003
Epoch [44/50], Loss: 0.007350316736847162
Epoch [45/50], Loss: 0.010187110863626003
Epoch [45/50], Loss: 0.010187110863626003
Epoch [46/50], Loss: 0.07060493528842926
Epoch [46/50], Loss: 0.07060493528842926
Epoch [47/50], Loss: 0.025322359055280685
Epoch [47/50], Loss: 0.025322359055280685
Epoch [48/50], Loss: 0.01949467323720455
Epoch [49/50], Loss: 0.022773098200559616
Epoch [50/50], Loss: 0.001823487225919962
Accuracy on the test set: 98.5%

(QMR) C:\Users\Administrator\Desktop\HUST-CV>C:/ProgramData/anaconda3/envs/QMR/python.exe c:/Users/Administrator/Desktop/HUST-CV/mlp/lab_qmr.py
Epoch [1/50], Loss: 0.6158584952354431
Epoch [11/50], Loss: 0.021802624687552452
Epoch [21/50], Loss: 0.06640477478504181
Epoch [31/50], Loss: 0.001183257787488401
Epoch [41/50], Loss: 0.043817076832056046
Accuracy on the test set: 98.0%

(QMR) C:\Users\Administrator\Desktop\HUST-CV>C:/ProgramData/anaconda3/envs/QMR/python.exe c:/Users/Administrator/Desktop/HUST-CV/mlp/lab_qmr.py
Epoch [1/50], Loss: 0.6542579531669617
Epoch [6/50], Loss: 0.0199209563434124
Epoch [11/50], Loss: 0.02712712436914444
Epoch [16/50], Loss: 0.04429348558187485
Epoch [21/50], Loss: 0.00997350923717022
Epoch [26/50], Loss: 0.029812734574079514
Epoch [31/50], Loss: 0.002254038117825985
Epoch [36/50], Loss: 0.02795606665313244
Epoch [41/50], Loss: 0.00477906409651041
Epoch [46/50], Loss: 0.00041997822700068355
Accuracy on the test set: 99.25%

(QMR) C:\Users\Administrator\Desktop\HUST-CV>C:/ProgramData/anaconda3/envs/QMR/python.exe c:/Users/Administrator/Desktop/HUST-CV/mlp/lab_qmr.py
Epoch [1/50], Loss: 0.7081524133682251
Epoch [5/50], Loss: 0.04637599736452103
Epoch [9/50], Loss: 0.018905771896243095
Epoch [13/50], Loss: 0.005938094574958086
Epoch [17/50], Loss: 0.051892317831516266
Epoch [21/50], Loss: 0.007578755728900433
Epoch [25/50], Loss: 0.0016273203073069453
Epoch [29/50], Loss: 0.0005599295836873353
Epoch [33/50], Loss: 0.016461113467812538
Epoch [37/50], Loss: 0.02073649875819683
Epoch [41/50], Loss: 0.03722808137536049
Epoch [45/50], Loss: 0.19947202503681183
Epoch [49/50], Loss: 0.0007041222997941077
Accuracy on the test set: 99.5%

(QMR) C:\Users\Administrator\Desktop\HUST-CV>C:/ProgramData/anaconda3/envs/QMR/python.exe c:/Users/Administrator/Desktop/HUST-CV/mlp/lab_qmr.py
Epoch [1/50], Loss: 1.1432151794433594
Epoch [5/50], Loss: 0.424778550863266
Epoch [9/50], Loss: 0.15931442379951477
Epoch [13/50], Loss: 0.07751275599002838
Epoch [17/50], Loss: 0.0729590654373169
Epoch [21/50], Loss: 0.026640450581908226
Epoch [25/50], Loss: 0.027256734669208527
Epoch [29/50], Loss: 0.06364866346120834
Epoch [33/50], Loss: 0.01086816843599081
Epoch [37/50], Loss: 0.014782466925680637
Epoch [41/50], Loss: 0.013351364061236382
Epoch [45/50], Loss: 0.028768200427293777
Epoch [49/50], Loss: 0.040534261614084244
Accuracy on the test set: 98.5%

(QMR) C:\Users\Administrator\Desktop\HUST-CV>C:/ProgramData/anaconda3/envs/QMR/python.exe c:/Users/Administrator/Desktop/HUST-CV/mlp/lab_qmr.py
Epoch [1/30], Loss: 0.6892160773277283
Epoch [3/30], Loss: 0.17988260090351105
Epoch [5/30], Loss: 0.20035728812217712
Epoch [7/30], Loss: 0.06904248893260956
Epoch [9/30], Loss: 0.023629266768693924
Epoch [11/30], Loss: 0.019998228177428246
Epoch [13/30], Loss: 0.02025420218706131
Epoch [15/30], Loss: 0.03667869791388512
Epoch [17/30], Loss: 0.005571408197283745
Epoch [19/30], Loss: 0.1259506344795227
Epoch [21/30], Loss: 0.013312643393874168
Epoch [23/30], Loss: 0.008125852793455124
Epoch [25/30], Loss: 0.1384403109550476
Epoch [27/30], Loss: 0.014341169036924839
Epoch [29/30], Loss: 0.022745030000805855
Accuracy on the test set: 99.0%

(QMR) C:\Users\Administrator\Desktop\HUST-CV>C:/ProgramData/anaconda3/envs/QMR/python.exe c:/Users/Administrator/Desktop/HUST-CV/mlp/lab_qmr.py
Epoch [1/30], Loss: 0.6334226131439209
Epoch [3/30], Loss: 0.0815151259303093
Epoch [5/30], Loss: 0.03710527345538139
Epoch [7/30], Loss: 0.021677624434232712
Epoch [9/30], Loss: 0.017231306061148643
Epoch [11/30], Loss: 0.012687326408922672
Epoch [13/30], Loss: 0.00769454101100564
Epoch [15/30], Loss: 0.03158435598015785
Epoch [17/30], Loss: 0.03828418254852295
Epoch [19/30], Loss: 0.1308438628911972
Epoch [21/30], Loss: 0.008844690397381783
Epoch [23/30], Loss: 0.00391450384631753
Epoch [25/30], Loss: 0.034330956637859344
Epoch [27/30], Loss: 0.023307155817747116
Epoch [29/30], Loss: 0.019259370863437653
Accuracy on the test set: 99.25%

